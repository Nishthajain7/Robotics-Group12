{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea99c0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-08 20:28:33.232867: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-08 20:28:33.240804: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-08 20:28:33.262808: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759935513.299184   49106 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759935513.309804   49106 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1759935513.339313   49106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759935513.339362   49106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759935513.339368   49106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759935513.339374   49106 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-10-08 20:28:33.348944: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13442ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MilitaryRoboticSystemMaintenance:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_names = None\n",
    "\n",
    "    def generate_synthetic_data(self, n_samples=1000):\n",
    "        df = pd.read_csv('smart_manufacturing_temperature_regulation.csv')\n",
    "        iot_df = pd.read_csv('industrial_fault_detection_data.csv')\n",
    "        robot_df = pd.read_csv('industrial_robot_control.csv')\n",
    "        np.random.seed(42)\n",
    "        current_temperature = df['Current Temperature (Â°C)'].values\n",
    "        setpoint_temperature = df['Setpoint Temperature (Â°C)'].values  \n",
    "        ambient_temperature = df['Ambient Temperature (Â°C)'].values\n",
    "        system_vibration = iot_df['Vibration (mm/s)'].values\n",
    "        hydraulic_pressure = iot_df['Pressure (bar)'].values\n",
    "        operational_hours = robot_df['task_duration'].values\n",
    "        current_draw = robot_df['energy_consumption'].values[:n_samples]\n",
    "\n",
    "        data = {\n",
    "        'system_temperature': current_temperature,\n",
    "        'power_unit_temperature': setpoint_temperature,\n",
    "        'ambient_temperature': ambient_temperature,\n",
    "        'system_vibration': system_vibration,\n",
    "        'hydraulic_pressure': hydraulic_pressure,\n",
    "        'current_draw': current_draw,\n",
    "        'operational_hours': operational_hours,\n",
    "        'previous_failures' : robot_df['error_rate'].values * 10,\n",
    "        }\n",
    "        failure_probability = (\n",
    "            0.3 * (data['system_temperature'] > 70).astype(int) +\n",
    "            0.4 * (data['power_unit_temperature'] > 80).astype(int) +\n",
    "            0.4 * (data['system_vibration'] > 2.0).astype(int) +\n",
    "            0.2 * (data['operational_hours'] > 4000).astype(int) +\n",
    "            0.3 * (data['previous_failures'] > 2).astype(int)\n",
    "        ) / 1.6\n",
    "        data['is_failure'] = np.random.binomial(1, failure_probability)\n",
    "        df = pd.DataFrame(data)\n",
    "        df['timestamp'] = pd.date_range(start='2024-01-01',\n",
    "        periods=n_samples, freq='h')\n",
    "        return df\n",
    "    def preprocess_data(self, data):\n",
    "        self.feature_names = [col for col in data.columns if col not in ['is_failure', 'timestamp']]\n",
    "        X = data[self.feature_names]\n",
    "        y = data['is_failure']\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        return train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "    def train_model(self, X_train, y_train):\n",
    "        self.model = RandomForestClassifier(\n",
    "        n_estimators=20,\n",
    "        max_depth=5,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42\n",
    "        )\n",
    "        self.model.fit(X_train, y_train)\n",
    "    def evaluate_model(self, X_test, y_test):\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        cm = confusion_matrix(y_test,\n",
    "        y_pred)\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        sns.heatmap(cm, annot=True, fmt='d',\n",
    "        cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.show()\n",
    "        # ROC Curve\n",
    "        y_pred_proba = self.model.predict_proba(X_test)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test,\n",
    "        y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    def verify_with_gru(self, X_train, X_test, y_train, y_test, epochs=30, batch_size=32):\n",
    "        X_test_rf = X_test\n",
    "        # ðŸ”¹ Reshape for GRU (3D)\n",
    "        X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "        X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "        \n",
    "        # Build GRU model\n",
    "        model = Sequential([\n",
    "            GRU(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False),\n",
    "            Dropout(0.3),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "        # Compile and train\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.2, verbose=1)\n",
    "        \n",
    "        # Predict on test set\n",
    "        y_pred_prob = model.predict(X_test)\n",
    "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "        \n",
    "        # Evaluate GRU\n",
    "        gru_f1 = f1_score(y_test, y_pred)\n",
    "        gru_acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"\\nâœ… GRU Model Evaluation:\")\n",
    "        print(f\"Accuracy: {gru_acc:.4f}\")\n",
    "        print(f\"F1 Score: {gru_f1:.4f}\")\n",
    "        \n",
    "        rf_pred = self.model.predict(X_test_rf)\n",
    "        rf_f1 = f1_score(y_test, rf_pred)\n",
    "        rf_acc = accuracy_score(y_test, rf_pred)\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Random Forest vs GRU Comparison:\")\n",
    "        print(f\"Random Forest - Accuracy: {rf_acc:.4f}, F1: {rf_f1:.4f}\")\n",
    "        print(f\"GRU Model     - Accuracy: {gru_acc:.4f}, F1: {gru_f1:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'random_forest': {'accuracy': rf_acc, 'f1': rf_f1},\n",
    "            'gru': {'accuracy': gru_acc, 'f1': gru_f1}\n",
    "        }\n",
    "\n",
    "    def analyze_feature_importance(self):\n",
    "        importances = self.model.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.title('Feature Importance for Failure Prediction')\n",
    "        plt.bar(range(len(importances)), importances[indices])\n",
    "        plt.xticks(range(len(importances)), [self.feature_names[i] for i in indices], rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    def correlation_heatmap(self, data):\n",
    "        correlation_matrix = data.corr()\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(correlation_matrix,\n",
    "        annot=True, fmt='.2f', cmap='coolwarm')\n",
    "        plt.title('Feature Correlation Heatmap')\n",
    "        plt.show()\n",
    "\n",
    "    def feature_distribution(self, data):\n",
    "        features = [\n",
    "        'system_temperature',\n",
    "        'power_unit_temperature',\n",
    "        'ambient_temperature',\n",
    "        'system_vibration',\n",
    "        'hydraulic_pressure',\n",
    "        'current_draw',\n",
    "        'operational_hours',\n",
    "        'previous_failures'\n",
    "        ]\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        for i, feature in enumerate(features):\n",
    "            plt.subplot(4, 4, i + 1)\n",
    "            sns.histplot(data, x=feature,\n",
    "            hue='is_failure', kde=True, bins=30,\n",
    "            palette='coolwarm')\n",
    "            plt.title(f'Distribution of {feature}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    def time_series_plot(self, data):\n",
    "        time_grouped = data.groupby(data['timestamp'].dt.date)['is_failure'].mean()\n",
    "        plt.figure()\n",
    "        plt.plot(time_grouped.index,time_grouped.values, marker='o',color='teal')\n",
    "        plt.title('Average Failure ProbabilityOver Time')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Failure Probability')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "    def predict_maintenance_needs(self,current_data):\n",
    "        scaled_data = self.scaler.transform(current_data[self.feature_names])\n",
    "        failure_prob = self.model.predict_proba(scaled_data)[:, 1]\n",
    "        predictions = pd.DataFrame({\n",
    "            'Failure_Probability': failure_prob,\n",
    "            'Risk_Level': pd.cut(failure_prob,\n",
    "        bins=[0, 0.3, 0.6, 1],\n",
    "        labels=['Low', 'Medium', 'High'])})\n",
    "        return predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
