{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea99c0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13442ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MilitaryRoboticSystemMaintenance:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.feature_names = None\n",
    "\n",
    "    def generate_synthetic_data(self, n_samples=1000):\n",
    "        df = pd.read_csv('smart_manufacturing_temperature_regulation.csv')\n",
    "        current_temperature = df['Current Temperature (Â°C)'].values\n",
    "        setpoint_temperature = df['Setpoint Temperature (Â°C)'].values  \n",
    "        ambient_temperature = df['Ambient Temperature (Â°C)'].values\n",
    "        np.random.seed(42)\n",
    "        data = {\n",
    "        'system_temperature': current_temperature,\n",
    "        'power_unit_temperature': setpoint_temperature,\n",
    "        'ambient_temperature': ambient_temperature,\n",
    "        'system_vibration': np.random.uniform(0.1, 2.5, n_samples),\n",
    "        'power_unit_vibration':  np.random.uniform(0.2, 3.0, n_samples),\n",
    "        'hydraulic_pressure': np.random.uniform(1000, 3000,n_samples),\n",
    "        'voltage_fluctuation': np.random.uniform(-0.5, 0.5, n_samples),\n",
    "        'current_draw': np.random.uniform(10, 30, n_samples),\n",
    "        'operational_hours': np.random.uniform(0, 5000, n_samples),\n",
    "        'duty_cycle': np.random.uniform(20, 90, n_samples),\n",
    "        'load_capacity': np.random.uniform(40, 100, n_samples),\n",
    "        'days_since_maintenance': np.random.uniform(0, 365, n_samples),\n",
    "        'previous_failures': np.random.poisson(0.5, n_samples)\n",
    "        }\n",
    "        failure_probability = (\n",
    "            0.3 * (data['system_temperature'] > 70).astype(int) +\n",
    "            0.4 * (data['power_unit_temperature'] > 80).astype(int) +\n",
    "            0.4 * (data['system_vibration'] > 2.0).astype(int) +\n",
    "            0.3 * (data['power_unit_vibration'] > 2.5).astype(int) +\n",
    "            0.2 * (data['operational_hours'] > 4000).astype(int) +\n",
    "            0.3 * (data['duty_cycle'] > 80).astype(int) +\n",
    "            0.4 * (data['days_since_maintenance'] > 300).astype(int) +\n",
    "            0.3 * (data['previous_failures'] > 2).astype(int)\n",
    "        ) / 2.7\n",
    "        data['is_failure'] = np.random.binomial(1, failure_probability)\n",
    "        df = pd.DataFrame(data)\n",
    "        df['timestamp'] = pd.date_range(start='2024-01-01',\n",
    "        periods=n_samples, freq='h')\n",
    "        return df\n",
    "    def preprocess_data(self, data):\n",
    "        self.feature_names = [col for col in data.columns if col not in ['is_failure', 'timestamp']]\n",
    "        X = data[self.feature_names]\n",
    "        y = data['is_failure']\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        return train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "    def train_model(self, X_train, y_train):\n",
    "        rf = RandomForestClassifier(random_state=42)\n",
    "        param_dist = {\n",
    "            'n_estimators': np.arange(50, 300, 50), \n",
    "            'max_depth': [5, 10, 15, 20, None],\n",
    "            'min_samples_split': [2, 5, 10, 20],\n",
    "            'min_samples_leaf': [1, 2, 4, 8],   \n",
    "            'max_features': ['sqrt', 'log2', None],\n",
    "            'bootstrap': [True, False]                 \n",
    "        }\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=rf,\n",
    "            param_distributions=param_dist,\n",
    "            n_iter=30,\n",
    "            cv=5,\n",
    "            scoring='f1',\n",
    "            verbose=1,\n",
    "            n_jobs=-1,\n",
    "            random_state=42\n",
    "        )\n",
    "        random_search.fit(X_train, y_train)\n",
    "        self.model = random_search.best_estimator_\n",
    "        return self.model\n",
    "    def evaluate_model(self, X_test, y_test):\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        cm = confusion_matrix(y_test,\n",
    "        y_pred)\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        sns.heatmap(cm, annot=True, fmt='d',\n",
    "        cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.show()\n",
    "        # ROC Curve\n",
    "        y_pred_proba = self.model.predict_proba(X_test)[:, 1]\n",
    "        fpr, tpr, _ = roc_curve(y_test,\n",
    "        y_pred_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.figure(figsize=(4, 4))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    def verify_with_gru(self, X_train, X_test, y_train, y_test, epochs=30, batch_size=32):\n",
    "        # Scale features for neural network\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        # Reshape input for GRU: (samples, timesteps, features)\n",
    "        # If your data isnâ€™t sequential, we treat each feature vector as a single time step\n",
    "        X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "        X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "        \n",
    "        # Build GRU model\n",
    "        model = Sequential([\n",
    "            GRU(64, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), return_sequences=False),\n",
    "            Dropout(0.3),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Train GRU\n",
    "        history = model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_split=0.2,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Predict on test set\n",
    "        y_pred_prob = model.predict(X_test_scaled)\n",
    "        y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "        \n",
    "        # Evaluate performance\n",
    "        gru_f1 = f1_score(y_test, y_pred)\n",
    "        gru_acc = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"\\nâœ… GRU Model Evaluation:\")\n",
    "        print(f\"Accuracy: {gru_acc:.4f}\")\n",
    "        print(f\"F1 Score: {gru_f1:.4f}\")\n",
    "        \n",
    "        # Compare with Random Forest\n",
    "        rf_pred = self.model.predict(X_test)\n",
    "        rf_f1 = f1_score(y_test, rf_pred)\n",
    "        rf_acc = accuracy_score(y_test, rf_pred)\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Random Forest vs GRU Comparison:\")\n",
    "        print(f\"Random Forest - Accuracy: {rf_acc:.4f}, F1: {rf_f1:.4f}\")\n",
    "        print(f\"GRU Model     - Accuracy: {gru_acc:.4f}, F1: {gru_f1:.4f}\")\n",
    "        \n",
    "        # Optional: return both modelsâ€™ scores for analysis\n",
    "        return {\n",
    "            'random_forest': {'accuracy': rf_acc, 'f1': rf_f1},\n",
    "            'gru': {'accuracy': gru_acc, 'f1': gru_f1}\n",
    "        }\n",
    "\n",
    "    def analyze_feature_importance(self):\n",
    "        importances = self.model.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.title('Feature Importance for Failure Prediction')\n",
    "        plt.bar(range(len(importances)), importances[indices])\n",
    "        plt.xticks(range(len(importances)), [self.feature_names[i] for i in indices], rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    def correlation_heatmap(self, data):\n",
    "        correlation_matrix = data.corr()\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(correlation_matrix,\n",
    "        annot=True, fmt='.2f', cmap='coolwarm')\n",
    "        plt.title('Feature Correlation Heatmap')\n",
    "        plt.show()\n",
    "\n",
    "    def feature_distribution(self, data):\n",
    "        features = [\n",
    "        'system_temperature',\n",
    "        'power_unit_temperature',\n",
    "        'ambient_temperature',\n",
    "        'system_vibration',\n",
    "        'power_unit_vibration',\n",
    "        'hydraulic_pressure',\n",
    "        'voltage_fluctuation',\n",
    "        'current_draw',\n",
    "        'operational_hours',\n",
    "        'duty_cycle',\n",
    "        'load_capacity',\n",
    "        'days_since_maintenance',\n",
    "        'previous_failures'\n",
    "        ]\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        for i, feature in enumerate(features):\n",
    "            plt.subplot(4, 4, i + 1)\n",
    "            sns.histplot(data, x=feature,\n",
    "            hue='is_failure', kde=True, bins=30,\n",
    "            palette='coolwarm')\n",
    "            plt.title(f'Distribution of {feature}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    def time_series_plot(self, data):\n",
    "        time_grouped = data.groupby(data['timestamp'].dt.date)['is_failure'].mean()\n",
    "        plt.figure()\n",
    "        plt.plot(time_grouped.index,time_grouped.values, marker='o',color='teal')\n",
    "        plt.title('Average Failure ProbabilityOver Time')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Failure Probability')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "    def predict_maintenance_needs(self,current_data):\n",
    "        scaled_data = self.scaler.transform(current_data[self.feature_names])\n",
    "        failure_prob = self.model.predict_proba(scaled_data)[:, 1]\n",
    "        predictions = pd.DataFrame({\n",
    "            'Failure_Probability': failure_prob,\n",
    "            'Risk_Level': pd.cut(failure_prob,\n",
    "        bins=[0, 0.3, 0.6, 1],\n",
    "        labels=['Low', 'Medium', 'High'])})\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f4a011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
